name: Daily Data Update
# Updated Python version to 3.10 for Streamlit compatibility
on:
  schedule:
    - cron: '0 7 * * *'  # 2 AM ET (7 AM UTC) daily
  workflow_dispatch:  # Allow manual triggering

jobs:
  check-matches:
    runs-on: ubuntu-latest
    outputs:
      has-matches: ${{ steps.check.outputs.has-matches }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Fetch upcoming fixtures
        run: python fetch_upcoming_fixtures.py

      - name: Check for tomorrow's matches
        id: check
        run: |
          if python check_tomorrow_matches.py; then
            echo "has-matches=true" >> $GITHUB_OUTPUT
            echo "Matches found for tomorrow - proceeding with data update"
          else
            echo "has-matches=false" >> $GITHUB_OUTPUT
            echo "No matches tomorrow - skipping data update"
          fi

  update-data:
    needs: check-matches
    if: needs.check-matches.outputs.has-matches == 'true'
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Run data pipeline
        run: |
          echo "Running data pipeline..."
          python combine_raw_data.py
          python prepare_model_data.py

      - name: Validate data
        run: |
          echo "Validating updated data..."
          python -c "
          import pandas as pd
          import os
          csv_path = 'data_files/combined_historical_data_with_calculations.csv'
          if os.path.exists(csv_path):
              df = pd.read_csv(csv_path, sep='\t')
              print(f'Data validation passed: {len(df)} rows')
              if len(df) < 1000:
                  raise ValueError('Data validation failed: insufficient rows')
          else:
              raise FileNotFoundError('Data file not found after pipeline')
          "

      - name: Commit and push changes
        run: |
          echo "Checking for changes..."
          git config --local user.email 'action@github.com'
          git config --local user.name 'GitHub Action'

          # Check if there are changes
          if git diff --quiet && git diff --staged --quiet; then
            echo "No changes to commit"
          else
            echo "Committing data updates..."
            git add data_files/
            git commit -m "Daily data update - $(date +'%Y-%m-%d')" || echo "No changes to commit"
            git push
            echo "Data update completed and pushed"
          fi

      - name: Notification on failure
        if: failure()
        run: |
          echo "Data pipeline failed - check logs for details"
          # Could add Slack/email notifications here in the future